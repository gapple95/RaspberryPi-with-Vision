{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Segmentation\n",
    "\n",
    "## 01-2. Segmentation ê°œë… ë° ì ìš©\n",
    "### Segmentationì´ë€?\n",
    "Segmentation(ë¶„í• )ì€ ì´ë¯¸ì§€ ë‚´ì˜ ê°œë³„ ê°ì²´ë‚˜ ì˜ì—­ì„ êµ¬ë¶„í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "- **Semantic Segmentation**: ê°™ì€ í´ë˜ìŠ¤ì˜ í”½ì…€ì„ ê·¸ë£¹í™” (ì˜ˆ: í•˜ëŠ˜, ë„ë¡œ, ì‚¬ëŒ ë“±)\n",
    "- **Instance Segmentation**: ê°œë³„ ê°ì²´ë¥¼ ë¶„ë¦¬ (ì˜ˆ: ê°ê°ì˜ ì‚¬ëŒ, ìë™ì°¨ êµ¬ë¶„)\n",
    "\n",
    "### YOLO-Seg vs. ê¸°ì¡´ Segmentation ê¸°ë²•\n",
    "| ê¸°ë²• | ì„¤ëª… | ì¥ì  | ë‹¨ì  |\n",
    "|------|------|------|------|\n",
    "| U-Net | CNN ê¸°ë°˜ ì˜ë£Œì˜ìƒ, ì¼ë°˜ ì´ë¯¸ì§€ ë¶„í• ì— í™œìš© | ë†’ì€ ì •í™•ë„, ê²½ëŸ‰í™” ê°€ëŠ¥ | ë¹„êµì  ì†ë„ê°€ ëŠë¦¼ |\n",
    "| DeepLabV3+ | Atrous convolution í™œìš©, ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë¶„í•  ê°€ëŠ¥ | ë†’ì€ ì •í™•ë„ | ëª¨ë¸ í¬ê¸°ê°€ í¬ê³  ì—°ì‚°ëŸ‰ì´ ë§ìŒ |\n",
    "| YOLO-Seg | YOLO ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì²´ ë¶„í•  | ë¹ ë¥¸ ì†ë„, ê°ì²´ ê°ì§€ì™€ ë¶„í•  ë™ì‹œ ìˆ˜í–‰ | ê¸°ì¡´ Segmentationë³´ë‹¤ ì„¸ë°€í•œ ì˜ì—­ êµ¬ë¶„ì´ ì•½í•  ìˆ˜ ìˆìŒ |\n",
    "\n",
    "### ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” Segmentation ëª¨ë¸\n",
    "- **TensorFlow Lite(TFLite) ê¸°ë°˜ ëª¨ë¸**: MobileNet+DeepLabV3\n",
    "- **YOLO-Seg TFLite ë³€í™˜ í›„ ì‚¬ìš©**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. [ì‹¤ìŠµ 8] TFLite ê¸°ë°˜ YOLO-Seg ì‹¤í–‰\n",
    "1. ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ YOLO-Seg ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜\n",
    "2. OpenCV ë° TFLiteë¡œ Segmentation ì‹¤í–‰\n",
    "3. ê²°ê³¼ ì‹œê°í™” ë° ì„±ëŠ¥ ì¸¡ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-1. YOLOv5nì„ í™œìš©í•œ ì‹¤ì‹œê°„ Segmentation\n",
    "\n",
    "### YOLOv5 git ë‹¤ìš´ë¡œë“œ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "```bash\n",
    "# YOLOv5 ì €ì¥ì†Œ í´ë¡ \n",
    "git clone https://github.com/ultralytics/yolov5.git\n",
    "cd yolov5\n",
    "\n",
    "# ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ë¼ì¦ˆë² ë¦¬íŒŒì´ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í¬í•¨)\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### yolov5n-seg ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n",
    "```bash\n",
    "mkdir weights\n",
    "wget -O weights/yolov5n-seg.pt https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n-seg.pt\n",
    "```\n",
    "\n",
    "### YOLOv5s ëª¨ë¸ì„ tflite ëª¨ë¸ë¡œ ë³€í™˜\n",
    "```bash\n",
    "python3 export.py --weights weights/yolov5n-seg.pt \\\n",
    "                 --include tflite \\\n",
    "                 --img 640 \\\n",
    "                 --device cpu\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO-segë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "```bash\n",
    "pip install numpy opencv-python tflite-runtime\n",
    "```\n",
    "\n",
    "### YOLO-seg ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 15:19:05.721703: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739773145.731160   24149 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739773145.733779   24149 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.lite as tflite\n",
    "\n",
    "# YOLOv5n-seg TFLite ëª¨ë¸ ë¡œë“œ\n",
    "interpreter = tflite.Interpreter(model_path=\"./yolov5/yolov5n-seg-fp16.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# ì…ë ¥ ë° ì¶œë ¥ í…ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ Threshold ì¡°ì •\n",
    "THRESHOLD = 0.5  \n",
    "\n",
    "# íˆ¬ëª…ë„ ì¡°ì ˆ (0.0 ~ 1.0)\n",
    "ALPHA = 0.5  \n",
    "\n",
    "# YOLO ëª¨ë¸ í•´ìƒë„ ì„¤ì • (ì›ë³¸ ë¹„ìœ¨ ìœ ì§€ X, YOLO í•™ìŠµ í¬ê¸° ìœ ì§€)\n",
    "YOLO_SIZE = 640  \n",
    "\n",
    "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (YOLO ëª¨ë¸ì´ í•™ìŠµí•œ ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ì ìš©)\n",
    "def preprocess_image(image_path, input_shape):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # YOLO ì…ë ¥ í¬ê¸°(640x640)ë¡œ ê°•ì œ ë¦¬ì‚¬ì´ì¦ˆ (ì›ë³¸ ë¹„ìœ¨ ìœ ì§€ X)\n",
    "    img_resized = cv2.resize(img, (YOLO_SIZE, YOLO_SIZE), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # YOLO ëª¨ë¸ ì…ë ¥ í˜•ì‹ ë³€í™˜\n",
    "    img_yolo = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    img_yolo = np.expand_dims(img_yolo, axis=0)  \n",
    "\n",
    "    return img_yolo, img_resized  # YOLO ì…ë ¥ìš© ì´ë¯¸ì§€ì™€ ì›ë³¸ ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ë°˜í™˜\n",
    "\n",
    "# ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ í•¨ìˆ˜\n",
    "def run_inference(image_path):\n",
    "    input_shape = input_details[0]['shape']\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (YOLO ì…ë ¥ í¬ê¸° ìœ ì§€)\n",
    "    input_data, resized_image = preprocess_image(image_path, input_shape)\n",
    "    \n",
    "    # ëª¨ë¸ì— ì…ë ¥ ë°ì´í„° ì„¤ì •\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # ëª¨ë¸ ì‹¤í–‰\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    segmentation_output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    # ì²« ë²ˆì§¸ í´ë˜ìŠ¤ ì„ íƒ\n",
    "    segmentation_mask = segmentation_output[0, 0, :, :]  \n",
    "\n",
    "    # Threshold ì ìš©\n",
    "    segmentation_mask = (segmentation_mask > THRESHOLD).astype(np.uint8) * 255  \n",
    "\n",
    "    # Gaussian Blur ì ìš©\n",
    "    segmentation_mask = cv2.GaussianBlur(segmentation_mask, (5, 5), 0)\n",
    "\n",
    "    # ì›ë³¸ í¬ê¸°ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ (ì›ë³¸ ë¹„ìœ¨ì´ ì•„ë‹Œ YOLO í•´ìƒë„ë¡œ ìœ ì§€)\n",
    "    mask_overlay = cv2.resize(segmentation_mask, (YOLO_SIZE, YOLO_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # ì»¬ëŸ¬ ë§ˆìŠ¤í¬ ìƒì„±\n",
    "    mask_colored = np.zeros((YOLO_SIZE, YOLO_SIZE, 3), dtype=np.uint8)\n",
    "    mask_colored[mask_overlay > 128] = [0, 255, 0]  \n",
    "\n",
    "    # ì›ë³¸ ì´ë¯¸ì§€ì™€ íˆ¬ëª…í•œ ë§ˆìŠ¤í¬ í•©ì„±\n",
    "    overlay_image = cv2.addWeighted(resized_image, 1 - ALPHA, mask_colored, ALPHA, 0)\n",
    "\n",
    "    return overlay_image\n",
    "\n",
    "# ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "image_path = \"test.jpg\"\n",
    "overlay_result = run_inference(image_path)\n",
    "\n",
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "cv2.imshow(\"Segmentation Overlay\", overlay_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Tracking\n",
    "## 03-1. Tracking ê°œë… ë° ì ìš©\n",
    "### Object Trackingì´ë€?\n",
    "Tracking(ì¶”ì )ì€ ë¹„ë””ì˜¤ í”„ë ˆì„ì—ì„œ ê°ì²´ë¥¼ ì‹ë³„í•˜ê³  ì—°ì†ëœ í”„ë ˆì„ì—ì„œ í•´ë‹¹ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì¶”ì í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì»´í“¨í„° ë¹„ì „ì—ì„œëŠ” ë‹¤ì–‘í•œ ë°©ì‹ì˜ íŠ¸ë˜í‚¹ ê¸°ë²•ì´ ì¡´ì¬í•˜ë©°, ê°ê°ì˜ ì•Œê³ ë¦¬ì¦˜ì€ ìƒí™©ì— ë”°ë¼ ì ì ˆí•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "- **Single Object Tracking(SOT)**: í•œ ê°œì˜ ê°ì²´ë¥¼ ì¶”ì  (e.g., KCF, CSRT)\n",
    "- **Multi-Object Tracking(MOT)**: ì—¬ëŸ¬ ê°ì²´ë¥¼ ë™ì‹œì— ì¶”ì  (e.g., SORT, DeepSORT, ByteTrack)\n",
    "\n",
    "## 03-2. Trackingì˜ ê¸°ë³¸ ì›ë¦¬\n",
    "íŠ¸ë˜í‚¹ì€ ê¸°ë³¸ì ìœ¼ë¡œ ê°ì²´ íƒì§€(Object Detection) + ì—°ì†ëœ í”„ë ˆì„ì—ì„œì˜ ìœ„ì¹˜ ì˜ˆì¸¡ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "### ê°ì²´ íƒì§€ (Object Detection)\n",
    "ê°ì²´ë¥¼ ì¶”ì í•˜ë ¤ë©´ ë¨¼ì € ê°ì²´ë¥¼ íƒì§€í•´ì•¼ í•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ YOLO, Faster R-CNN, SSD ê°™ì€ ë”¥ëŸ¬ë‹ ê¸°ë°˜ ëª¨ë¸ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "- **í•œ ë²ˆë§Œ íƒì§€(One-shot Detection)**: ì²« í”„ë ˆì„ì—ì„œë§Œ ê°ì²´ë¥¼ íƒì§€í•˜ê³  ì´í›„ì—ëŠ” ìœ„ì¹˜ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ì¶”ì  (e.g., Kalman Filter)\n",
    "- **ë§¤ í”„ë ˆì„ íƒì§€(Frame-by-Frame Detection)**: ë§¤ í”„ë ˆì„ë§ˆë‹¤ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ì—¬ ìœ„ì¹˜ë¥¼ ê°±ì‹  (e.g., YOLO + Tracking)\n",
    "\n",
    "### ê°ì²´ ë§¤ì¹­ (Object Association)\n",
    "ì´ì „ í”„ë ˆì„ê³¼ í˜„ì¬ í”„ë ˆì„ì˜ ê°ì²´ë¥¼ ì—°ê²°í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. íŠ¸ë˜í‚¹ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "- **IOU (Intersection over Union)**: ë‘ ê°œì˜ ë°”ìš´ë”© ë°•ìŠ¤ì˜ ê²¹ì¹˜ëŠ” ì˜ì—­ì„ ë¹„êµí•˜ì—¬ ê°™ì€ ê°ì²´ë¡œ ì¸ì‹\n",
    "- **Feature Matching**: ê°ì²´ì˜ íŠ¹ì§•ì (ORB, SIFT, SURF)ì„ ë¹„êµí•˜ì—¬ ë™ì¼í•œ ê°ì²´ íŒë³„\n",
    "- **ë”¥ëŸ¬ë‹ ê¸°ë°˜ Re-identification (Re-ID)**: CNNì„ ì´ìš©í•˜ì—¬ ê°ì²´ë¥¼ êµ¬ë³„í•˜ê³  ë™ì¼ ê°ì²´ì¸ì§€ íŒë³„\n",
    "\n",
    "### ì˜ˆì¸¡ ë° ë³´ì •\n",
    "ê°ì²´ì˜ ìœ„ì¹˜ëŠ” ë‹¤ìŒ í”„ë ˆì„ì—ì„œ ì–´ë””ì— ìˆì„ì§€ë¥¼ ì˜ˆì¸¡í•˜ê³ , ì´í›„ ì‹¤ì œ ì¸¡ì •ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ë³´ì •ë©ë‹ˆë‹¤.\n",
    "- **ì¹¼ë§Œ í•„í„° (Kalman Filter)**: ì„ í˜•ì ìœ¼ë¡œ ê°ì²´ì˜ ì›€ì§ì„ì„ ì˜ˆì¸¡í•˜ê³  ë³´ì •\n",
    "- **íŒŒí‹°í´ í•„í„° (Particle Filter)**: í™•ë¥  ë¶„í¬ë¥¼ í™œìš©í•˜ì—¬ ë¹„ì„ í˜•ì ì¸ ì›€ì§ì„ê¹Œì§€ ì¶”ì  ê°€ëŠ¥\n",
    "- **LSTM ê¸°ë°˜ ì˜ˆì¸¡**: ê°ì²´ì˜ ì´ë™ íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë†’ì„\n",
    "\n",
    "### ê°ì²´ ì¶”ì ì˜ í•„ìš”ì„±\n",
    "ê°ì²´ ì¶”ì ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë©ë‹ˆë‹¤.\n",
    "- **ììœ¨ ì£¼í–‰ ì°¨ëŸ‰**: ì°¨ëŸ‰ê³¼ ë³´í–‰ìì˜ ì›€ì§ì„ì„ ì¶”ì í•˜ì—¬ ì•ˆì „í•œ ì£¼í–‰ì„ ì§€ì›\n",
    "- **ìŠ¤í¬ì¸  ë¶„ì„**: ì„ ìˆ˜ë“¤ì˜ ì›€ì§ì„ì„ ì¶”ì í•˜ì—¬ ê²½ê¸° ë°ì´í„°ë¥¼ ë¶„ì„\n",
    "- **ê°ì‹œ ì‹œìŠ¤í…œ**: íŠ¹ì • ì¸ë¬¼ ë˜ëŠ” ì°¨ëŸ‰ì˜ ì´ë™ì„ ëª¨ë‹ˆí„°ë§\n",
    "- **ë¡œë´‡ ë¹„ì „**: ë¬¼ì²´ë¥¼ ë”°ë¼ê°€ê±°ë‚˜ íŠ¹ì •í•œ ëŒ€ìƒê³¼ ìƒí˜¸ì‘ìš©\n",
    "- **ì¦ê°• í˜„ì‹¤ (AR)**: ì‹¤ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì›€ì§ì„ì„ ì¶”ì í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì¸í„°í˜ì´ìŠ¤ ì œê³µ\n",
    "\n",
    "## 03-3. Tracking ì•Œê³ ë¦¬ì¦˜\n",
    "ê°ì²´ ì¶”ì ì„ ìœ„í•œ ëŒ€í‘œì ì¸ ì•Œê³ ë¦¬ì¦˜ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìœ¼ë©°, ìš©ë„ì— ë”°ë¼ ì ì ˆí•œ ë°©ì‹ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì „í†µì ì¸ íŠ¸ë˜í‚¹ ë°©ë²•\n",
    "| ì•Œê³ ë¦¬ì¦˜ | ì„¤ëª… |\n",
    "|----------|------|\n",
    "| **Mean-Shift** | íˆìŠ¤í† ê·¸ë¨ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë™í•˜ëŠ” ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì°¾ìŒ |\n",
    "| **CamShift** | Mean-Shiftë¥¼ ê°œì„ í•˜ì—¬ í¬ê¸° ë³€í™”ê¹Œì§€ ì¶”ì  ê°€ëŠ¥ |\n",
    "| **Optical Flow** | í”„ë ˆì„ ê°„ í”½ì…€ ì´ë™ì„ ê¸°ë°˜ìœ¼ë¡œ ê°ì²´ì˜ ì›€ì§ì„ì„ ì¶”ì  |\n",
    "| **Kalman Filter** | ì„ í˜• ì›€ì§ì„ì„ ê°€ì •í•˜ê³  ê°ì²´ì˜ ë‹¤ìŒ ìœ„ì¹˜ë¥¼ ì˜ˆì¸¡ |\n",
    "| **Particle Filter** | í™•ë¥  ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë¹„ì„ í˜• ì›€ì§ì„ì„ ì¶”ì  |\n",
    "\n",
    "### ë”¥ëŸ¬ë‹ ê¸°ë°˜ íŠ¸ë˜í‚¹ ë°©ë²•\n",
    "| ì•Œê³ ë¦¬ì¦˜ | ì„¤ëª… |\n",
    "|----------|------|\n",
    "| **SORT (Simple Online and Realtime Tracker)** | Kalman Filter + IOU ê¸°ë°˜ ì¶”ì  |\n",
    "| **DeepSORT** | SORTì— Re-IDë¥¼ ì¶”ê°€í•˜ì—¬ ì¬ì¸ì‹ ì„±ëŠ¥ í–¥ìƒ |\n",
    "| **ByteTrack** | SORTì˜ íƒì§€ë¥¼ ê°œì„ í•˜ì—¬ ì‹ ë¢°ë„ ë‚®ì€ ê°ì²´ë„ ì¶”ì  |\n",
    "| **FairMOT** | Multi-Object Trackingì„ ìœ„í•œ ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬ ì ìš© |\n",
    "| **Siamese Networks** | ìŒë‘¥ì´ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì²´ë¥¼ ê³„ì† ì¸ì‹ |\n",
    "| **Transformer ê¸°ë°˜ íŠ¸ë˜í‚¹ (TrackFormer)** | Transformer ëª¨ë¸ì„ í™œìš©í•œ ìµœì‹  íŠ¸ë˜í‚¹ ë°©ì‹ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 04. [ì‹¤ìŠµ 9] ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ Multi-Object Tracking ì ìš©\n",
    "1. YOLO + SORTë¥¼ ì ìš©í•œ MOT êµ¬í˜„\n",
    "2. OpenCV ê¸°ë°˜ ì‹¤ì‹œê°„ Tracking ìˆ˜í–‰\n",
    "3. ì„±ëŠ¥ ë¹„êµ ë° ìµœì í™” ë°©ì•ˆ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "```bash\n",
    "sudo apt update && sudo apt upgrade -y\n",
    "sudo apt install python3-pip python3-opencv libatlas-base-dev -y\n",
    "pip3 install torch torchvision numpy opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv5 ì„¤ì¹˜\n",
    "```bash\n",
    "git clone https://github.com/ultralytics/yolov5.git\n",
    "cd yolov5\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt to yolov5n.pt...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.87M/3.87M [00:01<00:00, 3.66MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv5 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# yolov5 í´ë”ë¥¼ ê²½ë¡œì— ì¶”ê°€\n",
    "sys.path.append(\"yolov5\")\n",
    "\n",
    "from yolov5.models.common import DetectMultiBackend\n",
    "from yolov5.utils.general import non_max_suppression\n",
    "\n",
    "# ë¼ì¦ˆë² ë¦¬íŒŒì´ CPU ëª¨ë“œ\n",
    "device = torch.device(\"cpu\")  # ë¬¸ìì—´ \"cpu\"ê°€ ì•„ë‹ˆë¼ torch.device ê°ì²´ ì‚¬ìš©\n",
    "model = DetectMultiBackend(\"yolov5n.pt\", device=device)\n",
    "model.eval()\n",
    "\n",
    "print(\"YOLOv5 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "\n",
    "```bash\n",
    "pip install supervision\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ğŸš€ v7.0-398-g5cdad892 Python-3.10.12 torch-2.6.0+cu124 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "sys.path.append(\"yolov5\")\n",
    "from yolov5.models.common import DetectMultiBackend\n",
    "from yolov5.utils.general import non_max_suppression\n",
    "from yolov5.utils.torch_utils import select_device\n",
    "\n",
    "# YOLOv5 ëª¨ë¸ ë¡œë“œ\n",
    "device = select_device('cpu')  # ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œëŠ” CPU ì‚¬ìš©\n",
    "model = DetectMultiBackend(\"yolov5n.pt\", device=device)\n",
    "model.eval()\n",
    "\n",
    "# ByteTrack íŠ¸ë˜ì»¤ ì´ˆê¸°í™”\n",
    "tracker = sv.ByteTrack()\n",
    "\n",
    "# âœ… ê°ì²´ì˜ ê¶¤ì (trajectory)ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "track_history = {}\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLOv5 ì…ë ¥ ì „ì²˜ë¦¬\n",
    "    img = cv2.resize(frame, (640, 640))\n",
    "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR â†’ RGB ë³€í™˜\n",
    "    img = np.ascontiguousarray(img, dtype=np.float32) / 255.0  # ì •ê·œí™”\n",
    "    img = torch.from_numpy(img).unsqueeze(0).to(device)\n",
    "\n",
    "    # ê°ì²´ íƒì§€ ìˆ˜í–‰\n",
    "    with torch.no_grad():\n",
    "        preds = model(img)\n",
    "        preds = non_max_suppression(preds, conf_thres=0.4, iou_thres=0.5)[0]\n",
    "\n",
    "    # íŠ¸ë˜í‚¹ì„ ìœ„í•œ Detections ê°ì²´ ìƒì„±\n",
    "    if preds is not None and len(preds) > 0:\n",
    "        xyxy = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for det in preds:\n",
    "            x1, y1, x2, y2, conf, cls = det[:6]\n",
    "            xyxy.append([x1, y1, x2, y2])\n",
    "            confidences.append(conf.item())  # Tensor â†’ float ë³€í™˜\n",
    "            class_ids.append(int(cls))\n",
    "\n",
    "        detections = sv.Detections(\n",
    "            xyxy=np.array(xyxy),\n",
    "            confidence=np.array(confidences),\n",
    "            class_id=np.array(class_ids),\n",
    "        )\n",
    "\n",
    "        # íŠ¸ë˜í‚¹ ì—…ë°ì´íŠ¸\n",
    "        tracks = tracker.update_with_detections(detections)\n",
    "\n",
    "        # íŠ¸ë˜í‚¹ëœ ê°ì²´ì— IDì™€ bounding box í‘œì‹œ\n",
    "        for i in range(len(tracks.xyxy)):\n",
    "            x1, y1, x2, y2 = map(int, tracks.xyxy[i])  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ\n",
    "            track_id = tracks.tracker_id[i]  # íŠ¸ë˜í‚¹ ID\n",
    "            \n",
    "            # âœ… IDë³„ë¡œ ê¶¤ì (trajectory) ì €ì¥\n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "\n",
    "            if track_id not in track_history:\n",
    "                track_history[track_id] = []\n",
    "\n",
    "            track_history[track_id].append((center_x, center_y))\n",
    "\n",
    "            # âœ… ê¶¤ì (trajectory) ì„  ê·¸ë¦¬ê¸°\n",
    "            for j in range(1, len(track_history[track_id])):\n",
    "                if track_history[track_id][j - 1] is None or track_history[track_id][j] is None:\n",
    "                    continue\n",
    "                cv2.line(frame, track_history[track_id][j - 1], track_history[track_id][j], (0, 255, 255), 2)\n",
    "\n",
    "            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"ID: {track_id}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # í™”ë©´ ì¶œë ¥\n",
    "    cv2.imshow(\"YOLOv5 + Supervision Tracking + Trajectory\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
