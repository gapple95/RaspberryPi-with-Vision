{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. OCRì„ í™œìš©í•œ ë¬¸ì ì¸ì‹\n",
    "\n",
    "## 01-1. OCR ê°œìš”\n",
    "\n",
    "### OCRì´ë€?\n",
    "OCR(Optical Character Recognition, ê´‘í•™ ë¬¸ì ì¸ì‹)ì€ ì´ë¯¸ì§€ ë‚´ì˜ í…ìŠ¤íŠ¸ë¥¼ ê°ì§€í•˜ê³  ì´ë¥¼ ë””ì§€í„¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. OCRì€ ë¬¸ì„œ ìë™í™”, ì°¨ëŸ‰ ë²ˆí˜¸íŒ ì¸ì‹, ì „ììƒê±°ë˜ ë° ê¸ˆìœµ ì„œë¹„ìŠ¤ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "### OCRì˜ í™œìš© ì‚¬ë¡€\n",
    "- **ë¬¸ì„œ ìŠ¤ìº” ë° ë””ì§€í„¸í™”**: ë¬¸ì„œë¥¼ ìŠ¤ìº”í•˜ì—¬ í¸ì§‘ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "- **ìë™ì°¨ ë²ˆí˜¸íŒ ì¸ì‹**: êµí†µ ê°ì‹œ ë° ì£¼ì°¨ ê´€ë¦¬ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "- **ë°”ì½”ë“œ ë° ì˜ìˆ˜ì¦ ì²˜ë¦¬**: ì‡¼í•‘ëª° ë° ë¬¼ë¥˜ ê´€ë¦¬ ì‹œìŠ¤í…œì—ì„œ í™œìš©ë©ë‹ˆë‹¤.\n",
    "- **ìì—°ì–´ ì²˜ë¦¬(NLP)ì™€ ê²°í•©**: OCRì„ í†µí•´ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.\n",
    "\n",
    "## 01-2. OCR ë™ì‘ ì›ë¦¬\n",
    "### ì „ì²˜ë¦¬ ë‹¨ê³„\n",
    "- **ì´ì§„í™”(Binarization)**: ì´ë¯¸ì§€ì˜ ë°°ê²½ê³¼ ë¬¸ìë¥¼ ë¶„ë¦¬í•˜ê¸° ìœ„í•´ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ í›„ Otsuâ€™s Thresholdingì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "- **ë…¸ì´ì¦ˆ ì œê±°**: ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬(Gaussian Blur) ë° ëª¨í´ë¡œì§€ ì—°ì‚°ì„ í™œìš©í•˜ì—¬ ë°°ê²½ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "- **ë¬¸ì ì •ë ¬ ë° ê¸°ìš¸ê¸° ë³´ì •**: Hough Transformì„ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ë¬¸ì ì¸ì‹ ê³¼ì •\n",
    "- **ì„¸ê·¸ë©˜í…Œì´ì…˜(Segmentation)**: ë¬¸ìë¥¼ ê°œë³„ì ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "- **í”¼ì²˜ ì¶”ì¶œ(Feature Extraction)**: ë¬¸ì íŒ¨í„´ì„ ì¶”ì¶œí•˜ì—¬ ë²¡í„°í™”í•©ë‹ˆë‹¤.\n",
    "- **ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì¸ì‹**: CNNê³¼ RNNì„ í™œìš©í•˜ì—¬ ë¬¸ìë¥¼ ë¶„ë¥˜í•˜ê³  í•´ì„í•©ë‹ˆë‹¤.\n",
    "\n",
    "## 01-3. ì£¼ìš” OCR ê¸°ìˆ \n",
    "### ì „í†µì ì¸ OCR ì—”ì§„\n",
    "- **Tesseract OCR** (Google ì§€ì›): ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì œê³µë˜ëŠ” ê°•ë ¥í•œ OCR ì—”ì§„ì…ë‹ˆë‹¤.\n",
    "  - LSTM ê¸°ë°˜ì˜ ë¬¸ì ì¸ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "  - ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ ì§€ì›í•˜ë©°, ì‚¬ìš©ì ì •ì˜ í•™ìŠµì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "  \n",
    "### ë”¥ëŸ¬ë‹ ê¸°ë°˜ OCR\n",
    "- **CRNN (Convolutional Recurrent Neural Network)**\n",
    "  - CNNì„ í†µí•´ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³  RNNì„ í™œìš©í•˜ì—¬ ë¬¸ë§¥ì„ ì´í•´í•˜ì—¬ OCR ì„±ëŠ¥ì„ í–¥ìƒí•©ë‹ˆë‹¤.\n",
    "- **EAST (Efficient and Accurate Scene Text Detector)**\n",
    "  - ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ê²€ì¶œì´ ê°€ëŠ¥í•˜ë©°, OpenCVì™€ TensorFlowì—ì„œ ì§€ì›ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 02. [ì‹¤ìŠµ 9] ë¼ì¦ˆë² ë¦¬íŒŒì´ OCR í™œìš©\n",
    "\n",
    "## 02-1. OpenCV + Tesseract\n",
    "\n",
    "### í™˜ê²½ ì„¤ì •\n",
    "```bash\n",
    "pip install opencv-python pytesseract\n",
    "sudo apt install tesseract-ocr\n",
    "\n",
    "# í•œê¸€ ì¸ì‹ì„ ì›í•  ê²½ìš°\n",
    "sudo apt install tesseract-ocr-kor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCVë¥¼ í™œìš©í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬\n",
    "ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë³´ë‹¤ ì˜ ì¶”ì¶œí•˜ê¸° ìœ„í•´ OpenCVë¥¼ í™œìš©í•˜ì—¬ ëŒ€ë¹„ ì¡°ì • ë° ì´ì§„í™”ë¥¼ ì ìš©í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ì‹ëœ í…ìŠ¤íŠ¸:\n",
      "JAVA Ol)\n",
      "\n",
      "JESUS PAID IT ALL\n",
      "\n",
      "SIN PAID\n",
      "SHAME map ae)\n",
      "REGRET mapa\n",
      "al UP ed Ee 4 t-) ep ae)\n",
      "UNF ORG I VENESS mPa\n",
      "HURT PAID\n",
      "ANGER PAID\n",
      "\n",
      "Subtotal\n",
      "\n",
      "nt 5 60\n",
      "\n",
      "PS ee Le 2 2 22 101017, meeearee\n",
      "\n",
      "Pod\n",
      "\n",
      "\"AND THEY SAID,\n",
      "BELIEVE ON THE LORD JESUS CHRIST,\n",
      "' AND THOU SHALT BE SAVED,\n",
      "AND THY HOUSE.\"\n",
      "ACTS 16:31\n",
      "\n",
      "LT\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¡œë“œ\n",
    "image = cv2.imread('sample_text.jpg')\n",
    "\n",
    "# ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ì´ì§„í™” ì²˜ë¦¬\n",
    "thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "# OCR ìˆ˜í–‰\n",
    "text = pytesseract.image_to_string(thresh, lang='eng')\n",
    "print(\"ì¸ì‹ëœ í…ìŠ¤íŠ¸:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-2. OpenCV + YOLO\n",
    "\n",
    "### YOLO ëª¨ë¸ ë¡œë“œ\n",
    "\n",
    "```bash\n",
    "wget https://github.com/Muhammad-Zeerak-Khan/Automatic-License-Plate-Recognition-using-YOLOv8/raw/main/license_plate_detector.pt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 license_plate, 2.6ms\n",
      "Speed: 1.4ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "ì¸ì‹ëœ ë²ˆí˜¸íŒ: \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "\n",
    "# í•™ìŠµëœ YOLOv8 ëª¨ë¸ ë¡œë“œ\n",
    "model = YOLO('license_plate_detector.pt')\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "image_path = 'sample_car.jpg'  # ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# YOLOv8ì„ ì‚¬ìš©í•˜ì—¬ ë²ˆí˜¸íŒ ê²€ì¶œ\n",
    "results = model(image)\n",
    "\n",
    "# ê²€ì¶œëœ ë²ˆí˜¸íŒì— ëŒ€í•œ OCR ìˆ˜í–‰\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "        # ë²ˆí˜¸íŒ ì˜ì—­ ì¶”ì¶œ\n",
    "        plate_image = image[y1:y2, x1:x2]\n",
    "\n",
    "        # OCR ì „ì²˜ë¦¬: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ ë° ì´ì§„í™”\n",
    "        gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "        # OCR ìˆ˜í–‰\n",
    "        text = pytesseract.image_to_string(thresh, config='--psm 7')\n",
    "        print(f'ì¸ì‹ëœ ë²ˆí˜¸íŒ: {text.strip()}')\n",
    "\n",
    "        # ê²°ê³¼ ì‹œê°í™”\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image, text.strip(), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ\n",
    "cv2.imshow('License Plate Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 license_plate, 3.3ms\n",
      "Speed: 1.5ms preprocess, 3.3ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "ğŸ” ì¸ì‹ëœ ë²ˆí˜¸íŒ 0: \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pytesseract\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLOv8 ë²ˆí˜¸íŒ ê²€ì¶œ ëª¨ë¸ ë¡œë“œ\n",
    "model = YOLO(\"license_plate_detector.pt\")\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¡œë“œ\n",
    "image_path = \"sample_car.jpg\"  # ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    raise FileNotFoundError(f\"ğŸš¨ ì˜¤ë¥˜: ì´ë¯¸ì§€ íŒŒì¼ '{image_path}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# YOLOë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆí˜¸íŒ íƒì§€\n",
    "results = model(image)\n",
    "\n",
    "# ë²ˆí˜¸íŒ ê²€ì¶œ ë° OCR ìˆ˜í–‰\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "        # ë²ˆí˜¸íŒ ì˜ì—­(ROI) ì˜ë¼ë‚´ê¸°\n",
    "        roi = image[y1:y2, x1:x2]\n",
    "\n",
    "        # ROI í™•ì¸ (ë²ˆí˜¸íŒì´ ì˜ ì˜ë ¸ëŠ”ì§€ ë³´ê¸° ìœ„í•´ ì¶œë ¥)\n",
    "        cv2.imshow(f\"License Plate ROI {i}\", roi)  # ê°œë³„ ë²ˆí˜¸íŒ í™•ì¸\n",
    "        cv2.imwrite(f\"license_plate_roi_{i}.jpg\", roi)  # íŒŒì¼ë¡œ ì €ì¥\n",
    "\n",
    "        # OCR ì „ì²˜ë¦¬\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "        # OCR ìˆ˜í–‰\n",
    "        text = pytesseract.image_to_string(thresh, config=\"--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜\")\n",
    "        text = text.strip()\n",
    "\n",
    "        print(f\"ğŸ” ì¸ì‹ëœ ë²ˆí˜¸íŒ {i}: {text}\")\n",
    "\n",
    "        # ê²€ì¶œëœ ë²ˆí˜¸íŒ ì‹œê°í™”\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "# ê²°ê³¼ ì´ë¯¸ì§€ ì¶œë ¥\n",
    "cv2.imshow(\"License Plate Detection\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
